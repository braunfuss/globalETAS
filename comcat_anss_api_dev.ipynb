{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dtm\n",
    "import matplotlib.dates as mpd\n",
    "import pytz\n",
    "import calendar\n",
    "import operator\n",
    "import sys\n",
    "#\n",
    "# TODO: it is probably time to say goodnight to Python 2.x support...\n",
    "import urllib\n",
    "# try:\n",
    "# \t# should work with python 3.x\n",
    "# \timport urllib.request, urllib.parse, urllib.error\n",
    "# except:\n",
    "# \tprint(\"failed while loading: urllib.request, urllib.parse, urllib.error.\\n probably Python 2.x?\")\n",
    "# \t#urllib.request.urlopen = urllib.urlopen\n",
    "\n",
    "# try:\n",
    "# \timport ullib2\n",
    "# except:\n",
    "# \tprint(\"failed while loading urllib and/or urllib. maybe python 3.x?\")\n",
    "\t\n",
    "#import urllib.request, urllib.error, urllib.parse\n",
    "import requests\n",
    "import numpy\n",
    "import math\n",
    "\n",
    "tzutc = pytz.timezone('UTC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComCat ANSS API:\n",
    "- Comcat is awesome, and it replaced the old ANSS API (that was basicaly a hack I did)\n",
    "- But it's bulky and difficult to install on HPC or managed systems\n",
    "- So there's a new API, which i think is even easier to use. we should reserve it as an option\n",
    "- ... and develop it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: \n",
    "# maybe move this to ANSS_tools, and develop on a branch like a grownup?\n",
    "#\n",
    "# here is the new ANSS-comcat portal:\n",
    "# https://earthquake.usgs.gov/earthquakes/search/\n",
    "#\n",
    "# and here is a sample results URL:\n",
    "# https://earthquake.usgs.gov/fdsnws/event/1/query.csv?starttime=2019-09-06%2000:00:00&endtime=2019-09-13%2023:59:59&maxlatitude=37&minlatitude=30&maxlongitude=-115&minlongitude=-122&minmagnitude=2.5&eventtype=earthquake&orderby=time\n",
    "#\n",
    "# it looks like we can just replace the URL and use a query string, rather than post syntax, and then emulate\n",
    "#. the remaining infrastructure. in fact, the hierarchal get_list() -> process_list_for_catalog() organization\n",
    "#. might not look so silly any longer, since we presumably only have to rewrite the very top layer.\n",
    "#\n",
    "#\n",
    "# copy some stuff from ANSS tools; we'll code this up here and then move it over:\n",
    "\n",
    "def anss_comcat_DateStr(x=dtm.datetime.now(pytz.timezone('UTC')), delim_dt='-', delim_tm=':', dt_tm_sep=' '):\n",
    "    # yoder, 13 july 2015: ANSS seems to have made some changes. these date formats are breaking. probalby a matter of leading 0's in dates; might be fractional seconds.\n",
    "    #yr=x.year\n",
    "    #mo=x.month\n",
    "    #dy=x.day\n",
    "    #hr=x.hour\n",
    "    #mn=x.minute\n",
    "    #sc=x.second\n",
    "    #ms=x.microsecond\n",
    "    #fsecs=float(sc) + float(ms)*(10**(-6.0))\n",
    "    #\n",
    "    yr = str(x.year)\n",
    "    mo = ('00' + str(x.month))[-2:]\n",
    "    dy = ('00' + str(x.day))[-2:]\n",
    "    hr = ('00' + str(x.hour))[-2:]\n",
    "    mn = ('00' + str(x.minute))[-2:]\n",
    "    sc = ('00' + str(x.second))[-2:]\n",
    "    #\n",
    "    # ANSS seems to be complaining about fractional seconds, so skip this and return integer seconds.\n",
    "    '''\n",
    "    ms=x.microsecond\n",
    "    fsecs=float(sc) + float(ms)*(10**(-6.0))\n",
    "    #\n",
    "    # trim extra zeros:\n",
    "    fsecs_str = str(fsecs)\n",
    "    while ('.' in fsecs_str and len(fsecs_str)>3 and fsecs_str[-1]=='0'):\n",
    "        fsecs_str = fsecs_str[:-1]\n",
    "    '''\n",
    "    #\n",
    "    #return '%s/%s/%s,%s:%s:%f' % (yr, mo, dy, hr, mn, fsecs)\n",
    "    #return '%s/%s/%s,%s:%s:%s' % (yr, mo, dy, hr, mn, sc)\n",
    "\n",
    "    return delim_dt.join([yr,mo,dy]) + dt_tm_sep + delim_tm.join([hr,mn,sc])\n",
    "    #\n",
    "# let's take this opportunity to revise our syntax and introduce class structure. We can maintain backwards\n",
    "# compatibility with a function wrapper.\n",
    "class ANSS_Comcat_catalog(object):\n",
    "    # TODO: datestring re-formatting is totally forked. need to figure that out...\n",
    "    #\n",
    "    anss_url = 'https://earthquake.usgs.gov/fdsnws/event/1/query.csv'\n",
    "    \n",
    "    def __init__(self, min_lon=-125., max_lon=-115., min_lat=32., max_lat=45., m_c=3.5,\n",
    "                 from_date=dtm.datetime(2000, 1,1, tzinfo=tzutc), to_date=dtm.datetime.now(tzutc),\n",
    "                 Nmax=None):\n",
    "        #\n",
    "        delim_dt = '-'\n",
    "        delim_tm = ':'\n",
    "        #\n",
    "        if to_date is None:\n",
    "            to_date = dtm.datetime.now(tzutc)\n",
    "        from_date = anss_comcat_DateStr(from_date, delim_dt=delim_dt, delim_tm=delim_tm, dt_tm_sep='%20')\n",
    "        to_date   = anss_comcat_DateStr(to_date, delim_dt=delim_dt, delim_tm=delim_tm, dt_tm_sep='%20')\n",
    "        #\n",
    "        #print('*** DEBUG: from_date:: {}'.format(from_date))\n",
    "        #print('*** DEBUT: to_date:: {}'.format(to_date))\n",
    "        #\n",
    "        # 'starttime':from_date, 'endtime':to_date,\n",
    "        anssPrams={  'minmagnitude':m_c, 'minlatitude':min_lat, 'maxlatitude':max_lat, 'minlongitude':min_lon, \n",
    "                   'maxlongitude':max_lon, \n",
    "                   'eventtype':'earthquake', 'orderby':'time', 'limit':Nmax\n",
    "                  }\n",
    "        anss_prams = {ky:vl for ky,vl in anssPrams.items() if not (vl in (chr(9), chr(32)) or vl is None)}\n",
    "        #\n",
    "        #\n",
    "        url_str = '{}?starttime={}&endtime={}&{}'.format(self.anss_url,from_date, to_date, \n",
    "                                                      urllib.parse.urlencode(anss_prams) )\n",
    "        # = 'https://earthquake.usgs.gov/fdsnws/event/1/query.csv?starttime=2019-09-01%2000:00:00&endtime=2019-09-14%2006:16:43&limit=500&minmagnitude=3.5&minlatitude=32.0&maxlatitude=45.0&minlongitude=-125.0&maxlongitude=-115.0&eventtype=earthquake&orderby=time'\n",
    "        #print('*** DEBUG:  ', url_str)\n",
    "        #f = urllib.request.urlretrieve(url_str)\n",
    "        #\n",
    "        self.__dict__.update({ky:val for ky,val in locals().items() if not ky in ('self', '__class__')})\n",
    "    #\n",
    "    @property\n",
    "    def f(self):\n",
    "        return self.get_f()\n",
    "    #\n",
    "    def get_f(self):\n",
    "        return urllib.request.urlopen(self.url_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***  b'time,latitude,longitude,depth,mag,magType,nst,gap,dmin,rms,net,id,updated,place,type,horizontalError,depthError,magError,magNst,status,locationSource,magSource\\n'\n",
      "***  b'2019-09-13T06:50:21.890Z,36.6031667,-121.202,6.03,3.82,mw,61,66,0.03413,0.09,nc,nc73271485,2019-09-14T05:05:46.011Z,\"10km NNW of Pinnacles, CA\",earthquake,0.15,0.43,,5,reviewed,nc,nc\\n'\n",
      "***  b'2019-09-10T20:21:49.840Z,33.594,-117.27,13.69,3.96,ml,178,21,0.06253,0.23,ci,ci38824959,2019-09-14T05:15:51.962Z,\"1km ESE of Wildomar, CA\",earthquake,0.12,0.29,0.151,333,reviewed,ci,ci\\n'\n",
      "***  b'2019-09-10T12:24:42.590Z,39.5272,-116.4999,9.4,3.8,ml,44,85.35,0.872,0.2833,nn,nn00703221,2019-09-11T12:25:50.008Z,\"46km E of Austin, Nevada\",earthquake,,2.7,0.21,17,reviewed,nn,nn\\n'\n",
      "***  b'2019-09-10T04:25:55.631Z,39.5419,-116.5599,9.1,4.6,ml,53,67.17,0.857,0.2275,nn,nn00703188,2019-09-11T04:27:01.615Z,\"45km E of Austin, Nevada\",earthquake,,2.2,0.27,23,reviewed,nn,nn\\n'\n",
      "***  b'2019-09-08T14:07:23.340Z,35.5815,-117.4133333,5.57,3.59,mw,49,37,0.04014,0.15,ci,ci38819223,2019-09-10T22:33:20.582Z,\"20km S of Trona, CA\",earthquake,0.14,0.35,,6,reviewed,ci,ci\\n'\n",
      "**  <http.client.HTTPResponse object at 0x1230a03c8>\n"
     ]
    }
   ],
   "source": [
    "obj =  ANSS_Comcat_catalog(from_date=dtm.datetime(2019, 9, 1))\n",
    "\n",
    "for rw in obj.f:\n",
    "    print('*** ', rw)\n",
    "\n",
    "print('** ', obj.f)\n",
    "obj.f.close()\n",
    "#    print('** ', rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def getANSStoFilehandler(lon=[-125, -115], lat=[32, 45], minMag=4.92, dates0=[dtm.datetime(2001,1,1, tzinfo=tzutc), dtm.datetime(2010, 12, 31, tzinfo=tzutc)], Nmax=999999):\n",
    "    # fetch data from ANSS; return a file handler.\n",
    "    #\n",
    "    # use urllib in \"post\" mode. an example from http://www.python.org/doc/current/library/urllib.html#urllib.FancyURLopener)\n",
    "    # using \"get\" (aka, query-string method; note the ?%s string at the end of the URL, this is a single pram call to .urlopen):\n",
    "    #\n",
    "    #>>> import urllib\n",
    "    #>>> params = urllib.urlencode({'spam': 1, 'eggs': 2, 'bacon': 0})\n",
    "    #>>> f = urllib.urlopen(\"http://www.musi-cal.com/cgi-bin/query?%s\" % params)\n",
    "    #>>> print f.read()\n",
    "    #\n",
    "    # using \"post\" (note this is a 2 pram call):\n",
    "    #>>> import urllib\n",
    "    #>>> params = urllib.urlencode({'spam': 1, 'eggs': 2, 'bacon': 0})\n",
    "    #>>> f = urllib.urlopen(\"http://www.musi-cal.com/cgi-bin/query\", params)\n",
    "    #>>> print f.read()\n",
    "    #\n",
    "    # make ANSS prams dictionary (thank james for the bash-template):\n",
    "    # ANSSquery has day-resolution:\n",
    "    # revision: ANSS has time resolution, but you have to replace \"-\" -> \"/\" and the \" \" (space) -> \",\"\n",
    "    #dates=[dtm.date(dates0[0].year, dates0[0].month, dates0[0].day), dtm.date(dates0[1].year, dates0[1].month, dates0[1].day)]\n",
    "    dates=dates0\n",
    "    datestr1 = anssDateStr(dates[0])\n",
    "    datestr2 = anssDateStr(dates[1])\n",
    "    #print datestr1, datestr2\n",
    "    #\n",
    "    #anssPrams={'format':'cnss', 'output':'readable', 'mintime':str(dates[0]).replace('-', '/'), 'maxtime':str(dates[1]).replace('-', '/'), 'minmag':str(minMag), 'minlat':lat[0], 'maxlat':lat[1], 'minlon':lon[0], 'maxlon':lon[1], 'etype':'E', 'searchlimit':Nmax}\n",
    "    # so this is better, but i think it is still limited to 1 second resolution.\n",
    "    #\n",
    "    anssPrams={'format':'cnss', 'output':'readable', 'mintime':datestr1, 'maxtime':datestr2, 'minmag':str(minMag), 'minlat':lat[0], 'maxlat':lat[1], 'minlon':lon[0], 'maxlon':lon[1], 'etype':b'E', 'searchlimit':Nmax}\n",
    "    #anssPrams={'format':b'cnss', 'output':b'readable', 'mintime':bytearray(datestr1, 'utf-8'), 'maxtime':bytearray(datestr2, 'utf-8'), 'minmag':bytearray(str(minMag), 'utf-8'), 'minlat':lat[0], 'maxlat':lat[1], 'minlon':lon[0], 'maxlon':lon[1], 'etype':b'E', 'searchlimit':Nmax}\n",
    "    #print \"debug: \", anssPrams\n",
    "    #post_data = urllib.parse.urlencode(anssPrams)\n",
    "    #binary_post_data = post_data.encode('ascii')\n",
    "    #\n",
    "    # now, let's support some backwards compatibility, at least for a little while:\n",
    "    if sys.version_info.major == 2:\n",
    "        # old python...\n",
    "        f = urllib.urlopen('http://www.ncedc.org/cgi-bin/catalog-search2.pl', urllib.urlencode(anssPrams))\n",
    "    else:\n",
    "        binary_post_data = urllib.parse.urlencode(anssPrams).encode('ascii')\n",
    "        f = urllib.request.urlopen('http://www.ncedc.org/cgi-bin/catalog-search2.pl', binary_post_data )\n",
    "    #\n",
    "    # we might return f, a string of f, or maybe a list of lines from f. we'll work that out shortly...\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'urllib.urlretrieve'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-85e495a429a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'urllib.urlretrieve'"
     ]
    }
   ],
   "source": [
    "import urllib.urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://earthquake.usgs.gov/fdsnws/event/1/query.csv?starttime=2019-09-06%2000:00:00&endtime=2019-09-13%2023:59:59&\n",
    "        maxlatitude=35&minlatitude=31&maxlongitude=-113&minlongitude=-118&minmagnitude=2.5&maxmagnitude=9&\n",
    "        mindepth=-1&maxdepth=300&eventtype=earthquake&orderby=time&limit=500\n",
    "        \n",
    "\n",
    "https://earthquake.usgs.gov/fdsnws/event/1/query.csv?starttime=2019-09-01%2000:00:00&endtime=2019-09-14%2006:16:43&\n",
    "                    minmagnitude=3.5&minlatitude=32.0&maxlatitude=45.0&minlongitude=-125.0&maxlongitude=-115.0&\n",
    "                    eventtype=earthquake&orderby=time&limit=500\n",
    "                    \n",
    "https://earthquake.usgs.gov/fdsnws/event/1/query.csv?starttime=2019-09-01%2000:00:00&endtime=2019-09-14%2006:16:43&limit=500&minmagnitude=3.5\n",
    "                    \n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
