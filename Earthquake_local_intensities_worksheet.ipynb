{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dtm\n",
    "import matplotlib.dates as mpd\n",
    "import pytz\n",
    "tzutc = pytz.timezone('UTC')\n",
    "\n",
    "#import operator\n",
    "import math\n",
    "import random\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.optimize as spo\n",
    "from scipy import interpolate\n",
    "import scipy.constants\n",
    "import itertools\n",
    "import sys\n",
    "#import scipy.optimize as spo\n",
    "import os\n",
    "import operator\n",
    "#from PIL import Image as ipp\n",
    "import multiprocessing as mpp\n",
    "#\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import json\n",
    "import pickle\n",
    "#\n",
    "\n",
    "import geopy.distance\n",
    "#from geopy.distance import vincenty\n",
    "#from geopy.distance import great_circle\n",
    "#\n",
    "#import shapely.geometry as sgp\n",
    "os.environ['PROJ_LIB'] = '{}/anaconda3/share/proj'.format(os.getenv('HOME'))\n",
    "#\n",
    "from mpl_toolkits.basemap import Basemap as Basemap\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from geographiclib.geodesic import Geodesic as ggp\n",
    "#\n",
    "\n",
    "#import ANSStools as atp\n",
    "from yodiipy import ANSStools as atp\n",
    "#\n",
    "import contours2kml\n",
    "import globalETAS as gep\n",
    "\n",
    "#import global_etas_auto as ggep\n",
    "\n",
    "from eq_params import *\n",
    "#\n",
    "from nepal_figs import *\n",
    "import optimizers\n",
    "#\n",
    "import random\n",
    "import geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etas_prams:  {'incat': None, 'lats': [32.0, 38.0], 'lons': [-117.0, -114.0], 'mc': 2.5, 'date_range': ['1990-1-1', None], 'D_fract': 1.5, 'd_lambda': 1.76, 'd_tau': 2.28, 'fit_factor': 1.5, 'p': 1.1, 'q': 1.5, 'dmstar': 1.0, 'b1': 1.0, 'b2': 1.5, 'do_recarray': False}\n",
      "results fetched.\n"
     ]
    }
   ],
   "source": [
    "# let's just get a catalog and pull an earthquake out of it.\n",
    "n_cpu=None\n",
    "#\n",
    "lat0 = 35.705\n",
    "lon0 = -117.506\n",
    "#\n",
    "#ll_sacramento = (lon0, lat0)\n",
    "\n",
    "#m0 = 7.8\n",
    "\n",
    "d_lat=2.\n",
    "d_lon=2.\n",
    "#\n",
    "lats = [lat0-d_lat, lat0+d_lat]\n",
    "lons = [lon0-d_lon, lon0+d_lon]\n",
    "#\n",
    "to_dt = dtm.datetime(2019,7,6, tzinfo=tzutc)\n",
    "eq_prams = {'do_recarray': True, 'D_fract': 1.5,\n",
    "               't_0':dtm.datetime(1990, 1, 1, 0, 0, 0, tzinfo=tzutc),\n",
    "               't_now':to_dt, 't_future':None ,\n",
    "               'lats': lats, 'p_cat': 1.1, 'b1': 1.0, 'mc': 2.5, 'q_cat': 1.5,\n",
    "               'p_etas':1.1, 'q_etas':1.5,\n",
    "               'lons': lons, 'dmstar': 1.0, 'b2': 1.5, 'd_tau': 2.28,\n",
    "               'incat': None, 'fit_factor': 2.0, 'd_lambda': 1.76, 'etas_range_padding':1.5,\n",
    "            'etas_range_factor':30.0, 'ab_ratio_expon':.25 }\n",
    "eq_prams['mc'] = 6.7\n",
    "eq_prams['t0'] = dtm.datetime(2019,6,20, 0,0,0,0, tzinfo=pytz.timezone('UTC'))\n",
    "#\n",
    "\n",
    "mycat = atp.cat_from_anss_comcat(lon=lons, lat=lats, minMag=2.5,\n",
    "                        dates0=[dtm.datetime(2005,1,1, tzinfo=pytz.timezone('UTC')), \n",
    "                                dtm.datetime.now(pytz.timezone('UTC'))],\n",
    "                            Nmax=None, fout=None, rec_array=True)\n",
    "#                        dates0=[dtm.datetime(2005,1,1, tzinfo=tzutc), None], Nmax=None, fout=None, rec_array=True)\n",
    "\n",
    "mycat = gep.make_ETAS_catalog_mpp(incat=mycat, n_cpu=n_cpu)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mainshock:  ('2019-07-06T03:19:53.040000', 35.7695, -117.5993333, 7.1, 8., 737246.13880833, 61.65950019, 1277.03847158, 1.40581446e-05, 18.62087137, 165.68091867, 0.00150686, 1., 1.1, 1.5, 26.80175629, [0.09050061, 0.05666743], [[ 0.82796634,  0.56077779], [-0.56077779,  0.82796634]], 3225.)\n"
     ]
    }
   ],
   "source": [
    "for rw in mycat:\n",
    "    if rw['mag']>7.0:\n",
    "        eq_ms = rw\n",
    "    #\n",
    "#\n",
    "print('mainshock: ', eq_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = gep.Earthquake(eq_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0225408109874048e-12\n",
      "8.312145139055901e-13\n"
     ]
    }
   ],
   "source": [
    "print(eq.local_intensity(lon=-117., lat=35.) )\n",
    "print(eq.local_intensity(lon=-117., lat=34.) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165.68091866556017, 737340.6393351462, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq.t_0, eq.t_1, eq.t_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = numpy.linspace(eq.t_1, eq.t_1+100, 100)\n",
    "\n",
    "#ts[20] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** orates:  [0.00089983 0.00089983 0.00089983 0.00089983 0.00089983 0.00089983\n",
      " 0.00089982 0.00089982 0.00089982 0.00089982 0.00089982 0.00089982\n",
      " 0.00089982 0.00089982 0.00089981 0.00089981 0.00089981 0.00089981\n",
      " 0.00089981 0.00089981 0.00089981 0.00089981 0.00089981 0.0008998\n",
      " 0.0008998  0.0008998  0.0008998  0.0008998  0.0008998  0.0008998\n",
      " 0.0008998  0.00089979 0.00089979 0.00089979 0.00089979 0.00089979\n",
      " 0.00089979 0.00089979 0.00089979 0.00089978 0.00089978 0.00089978\n",
      " 0.00089978 0.00089978 0.00089978 0.00089978 0.00089978 0.00089977\n",
      " 0.00089977 0.00089977 0.00089977 0.00089977 0.00089977 0.00089977\n",
      " 0.00089977 0.00089976 0.00089976 0.00089976 0.00089976 0.00089976\n",
      " 0.00089976 0.00089976 0.00089976 0.00089975 0.00089975 0.00089975\n",
      " 0.00089975 0.00089975 0.00089975 0.00089975 0.00089975 0.00089974\n",
      " 0.00089974 0.00089974 0.00089974 0.00089974 0.00089974 0.00089974\n",
      " 0.00089974 0.00089973 0.00089973 0.00089973 0.00089973 0.00089973\n",
      " 0.00089973 0.00089973 0.00089973 0.00089972 0.00089972 0.00089972\n",
      " 0.00089972 0.00089972 0.00089972 0.00089972 0.00089972 0.00089972\n",
      " 0.00089971 0.00089971 0.00089971 0.00089971]\n"
     ]
    }
   ],
   "source": [
    "#orates = eq.omori_rate(t=ts)\n",
    "# this works, but eq.orate() does not; eq.orate() fails on some sort of validation (.any(), .all() reference)\n",
    "orates = 1./(eq.tau*(eq.t_0 + ts))\n",
    "\n",
    "print('** orates: ', orates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** orates:  [0.00089983 0.00089983 0.00089983 0.00089983 0.00089983 0.00089983\n",
      " 0.00089982 0.00089982 0.00089982 0.00089982 0.00089982 0.00089982\n",
      " 0.00089982 0.00089982 0.00089981 0.00089981 0.00089981 0.00089981\n",
      " 0.00089981 0.00089981 0.00089981 0.00089981 0.00089981 0.0008998\n",
      " 0.0008998  0.0008998  0.0008998  0.0008998  0.0008998  0.0008998\n",
      " 0.0008998  0.00089979 0.00089979 0.00089979 0.00089979 0.00089979\n",
      " 0.00089979 0.00089979 0.00089979 0.00089978 0.00089978 0.00089978\n",
      " 0.00089978 0.00089978 0.00089978 0.00089978 0.00089978 0.00089977\n",
      " 0.00089977 0.00089977 0.00089977 0.00089977 0.00089977 0.00089977\n",
      " 0.00089977 0.00089976 0.00089976 0.00089976 0.00089976 0.00089976\n",
      " 0.00089976 0.00089976 0.00089976 0.00089975 0.00089975 0.00089975\n",
      " 0.00089975 0.00089975 0.00089975 0.00089975 0.00089975 0.00089974\n",
      " 0.00089974 0.00089974 0.00089974 0.00089974 0.00089974 0.00089974\n",
      " 0.00089974 0.00089973 0.00089973 0.00089973 0.00089973 0.00089973\n",
      " 0.00089973 0.00089973 0.00089973 0.00089972 0.00089972 0.00089972\n",
      " 0.00089972 0.00089972 0.00089972 0.00089972 0.00089972 0.00089972\n",
      " 0.00089971 0.00089971 0.00089971 0.00089971]\n"
     ]
    }
   ],
   "source": [
    "print('** orates: ', orates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('** evecs, evals: ', eq.e_vals, eq.e_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lons_lats = numpy.array([[lon, lat] for lon,lat in itertools.product(numpy.linspace(eq.lon-2., eq.lon+2., 20),\n",
    "                                                numpy.linspace(eq.lat-2., eq.lat+2., 20))])\n",
    "#\n",
    "# for rw in lons_lats:\n",
    "#     print(rw)\n",
    "#\n",
    "local_intensities = eq.local_intensities(ts=ts, lons=lons_lats[:,0], lats=lons_lats[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 400)\n"
     ]
    }
   ],
   "source": [
    "print(local_intensities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globalETAS import Earthquake, deg2kmn\n",
    "#\n",
    "class NETAS_block(Earthquake):\n",
    "    # Note: it might make more sense to include an Earthquke(), or list of Earthquake()s rather than subclassing.\n",
    "    #. For batched MPP, for example, it would be possible to pre-construct a complete array of sites for multiple\n",
    "    #  inputs (Earthquake()s). On the other hand, that introduces some opportunity for memory mis-management, \n",
    "    #. mistakes, or requiring indexing (aka, you have earthquakes that are not close together, maybe non-\n",
    "    #. contiguous lattice sites)...\n",
    "    def __init__(self, times=None, sptial_intensity_threshold=1e3, time_intensity_threshold=None, \n",
    "                 lon_0=0., lat_0=0., d_lon=.1, d_lat=.1,\n",
    "                 *args, **kwargs):\n",
    "        '''\n",
    "        # @times: an iterable of times\n",
    "        # @intensity_threshold: compute range by invertng spatial-omori; solve for 1/this.\n",
    "        # @time_intensity_threshold: same, but for temporal distributionza\n",
    "        # @lon_0, lat_0 : zero-point for lon, lat bins, respectively.\n",
    "        # # parent array binning:\n",
    "        #\n",
    "        # TODO: what is the best parent binning convention? allow negative bins indices? Maybe we just\n",
    "        #. leave that up to the parent object. I think that, by itself, negative index labels, centered\n",
    "        #. on LL=[0,0] is most intuitive.\n",
    "        # @d_lon, d_lat : lon, lat bin sizes, respectively\n",
    "        #. bin indices are then j = int((lon - lon_0)/d_lon), k = int( (lat - lat_0)/d_lat)\n",
    "        # \n",
    "        # parent __init__(): __init__(self, dict_or_recarray, transform_type='equal_area', transform_ratio_max=5.,\n",
    "            ab_ratio_expon=.5, t_1=None, t_2=None)\n",
    "        #\n",
    "        '''\n",
    "        #\n",
    "        super(NETAS_block, self).__init__(*args, **kwargs)\n",
    "        #\n",
    "        # now, compute the spatial range and optionally the temporal range, or more specifically\n",
    "        #   the lon, lat, time dimensions/indices. compute these as pairs: [[k_label, value], ...]\n",
    "        #.  k_label: the index \"label\", or the index in a larger (global) lattice.\n",
    "        #.  an we use their ordering for direct indexing.\n",
    "        delta_lat = self.etas_range()/deg2km\n",
    "        delta_lon = delta_lat*numpy.cos(self.lat*scipy.constants.deg)\n",
    "        #\n",
    "        lat_min = int((self.lat - delta_lat)/d_lat)*d_lat\n",
    "        lon_min = int((self.lon - delta_lon)/d_lon)*d_lon\n",
    "        #\n",
    "        self.__dict__.update({'delta_lat':delta_lat, 'delta_lon':delta_lon, 'lat_min':lat_min, 'lon_min':lon_min})\n",
    "        #\n",
    "        # TODO: write these as functions to save memory? They will typically be called once\n",
    "        #. and then return a 2D array of intensities.\n",
    "        #lats = numpy.arange(lat_min, lat_min + 2*delta_lat, d_lat)\n",
    "        #lats_index_labels = ((lats-lat_0)/d_lat).astype(int)\n",
    "        #\n",
    "        #lons = numpy.arange(lon_min, lon_min + 2*delta_lon, d_lon)\n",
    "        #lons_index_labels = ((lons-lon_0)/d_lon).astype(int)\n",
    "    #\n",
    "    @property\n",
    "    def lats(self):\n",
    "        # TODO: are we de-modularizing too much here? I think maybe we just compute lats and lons\n",
    "        #. at this level. we leave the binning to the calling function. \n",
    "        #lats = numpy.arange(self.lat_min, self.lat_min + 2*self.delta_lat, self.d_lat)\n",
    "        #lats_index_labels = ((self.lats-self.lat_0)/self.d_lat).astype(int)\n",
    "        #\n",
    "        #return numpy.core.records.fromarrays([lats_index_labels, lats], dtype=[('index', '>i8'), ('lat', '>f8')])\n",
    "        return numpy.arange(self.lat_min, self.lat_min + 2*self.delta_lat, self.d_lat)\n",
    "                                    \n",
    "    @property\n",
    "    def lons(self):\n",
    "        #lons = numpy.arange(self.lon_min, self.lon_min + 2*self.delta_lon, self.d_lon)\n",
    "        #lons_index_labels = ((self.lons - self.lon_0)/self.d_lon).astype(int)\n",
    "        #\n",
    "        #return numpy.core.records.fromarrays([lons_index_labels, lons], dtype=[('index', '>i8'), ('lat', '>f8')])\n",
    "        return numpy.arange(self.lon_min, self.lon_min + 2*self.delta_lon, self.d_lon)\n",
    "    #\n",
    "    def etas_range(self, spatial_intensity_threshold=None):\n",
    "        spatial_intensity_threshold = spatial_intensity_threshold or self.spatial_intensity_threshold\n",
    "        if spatial_intensity_threshold is None:\n",
    "            return None\n",
    "        #\n",
    "        return self.r_0*(spatial_intensity_threshold**(1./self.q) - 1.)\n",
    "    #\n",
    "    def etas_temporal_range(self, time_intensity_threshold=None):\n",
    "        time_intensity_threshold = time_intensity_threshold or self.time_intensity_threshold\n",
    "        if time_intensity_threshold is None:\n",
    "            return None\n",
    "        #\n",
    "        return self.t_0*(time_intensity_threshold**(1./self.p) - 1.)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**  6.283185307179586\n"
     ]
    }
   ],
   "source": [
    "print('** ', scipy.constants.degree*360.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.41622246  1.12833884  0.55006882  2.2878234  11.55561806 10.61805146\n",
      "  7.55655403  0.30058825 11.84921565 11.08422654 18.09237713 19.52212661\n",
      "  7.52433627 14.53836665 18.28883357 10.15502936  8.66872371  9.05863425\n",
      " 18.3804989   8.78981498]\n",
      "[17  1  0  2 11 10  7  0 11 11 18 19  7 14 18 10  8  9 18  8]\n"
     ]
    }
   ],
   "source": [
    "A = numpy.random.random(20)*20\n",
    "print(A)\n",
    "print(A.astype(int) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.  5.1 5.2 5.3 5.4 5.5 5.6 5.7 5.8 5.9 6.  6.1 6.2 6.3 6.4 6.5 6.6 6.7\n",
      " 6.8 6.9 7.  7.1 7.2 7.3 7.4 7.5 7.6 7.7 7.8 7.9 8.  8.1 8.2 8.3 8.4 8.5\n",
      " 8.6 8.7 8.8 8.9 9.  9.1 9.2 9.3 9.4 9.5 9.6 9.7 9.8 9.9]\n"
     ]
    }
   ],
   "source": [
    "print(numpy.arange(5,10,.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** -190.0 : 170.0\n",
      "** -120.0 : -120.0\n",
      "** -115.0 : -115.0\n",
      "** 120.0 : 120.0\n",
      "** 115.0 : 115.0\n",
      "** 190.0 : -170.0\n"
     ]
    }
   ],
   "source": [
    "def f_lon(x):\n",
    "    return (x+180)%360. - 180\n",
    "\n",
    "for x in [-190., -120., -115., 120., 115., 190.]:\n",
    "    print('** {} : {}'.format(x, f_lon(x)))\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
